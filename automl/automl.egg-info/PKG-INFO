Metadata-Version: 2.4
Name: automl
Version: 0.1.0
Summary: AutoML pipeline for classification and regression
Author-email: Vanessa <vanessa.antivackis.etu@univ-lemans.fr>
License: MIT
Keywords: automl,machine-learning,sklearn,optuna
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: numpy>=1.21
Requires-Dist: pandas>=1.3
Requires-Dist: scikit-learn>=1.0
Requires-Dist: optuna>=3.0
Requires-Dist: scipy>=1.7
Requires-Dist: xgboost>=1.5
Requires-Dist: lightgbm>=3.3
Requires-Dist: catboost>=1.0
Provides-Extra: dev
Requires-Dist: pytest; extra == "dev"
Requires-Dist: black; extra == "dev"
Requires-Dist: flake8; extra == "dev"

# ğŸ¤– AutoML

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![scikit-learn](https://img.shields.io/badge/sklearn-1.0+-orange.svg)](https://scikit-learn.org/)

**AutoML** est un pipeline automatique de Machine Learning qui dÃ©tecte le type de problÃ¨me, nettoie les donnÃ©es et teste plusieurs modÃ¨les pour trouver le meilleur.

---

## âœ¨ FonctionnalitÃ©s

| FonctionnalitÃ© | Description |
|----------------|-------------|
| ğŸ” **DÃ©tection automatique** | Classification binaire, multi-classe, multi-label, rÃ©gression |
| ğŸ§¹ **Nettoyage intelligent** | Imputation, encodage, scaling, gestion sparse/high-dim |
| ğŸ¯ **Optimisation Optuna** | Recherche automatique des hyperparamÃ¨tres |
| âš¡ **ParallÃ©lisation** | Multiprocessing avec gestion mÃ©moire |
| ğŸ’¾ **Checkpoints** | Reprise automatique en cas d'interruption |
| ğŸ“Š **2 modes** | `stable` (rapide) et `explo` (exhaustif) |

---

## ğŸ“¦ Installation

### Depuis les sources

```bash
git clone git@git-ssh.univ-lemans.fr:s2504630/master-1-automl.git
cd automl
pip install -e .
```

### DÃ©pendances

```bash
pip install -r requirements.txt
```

**DÃ©pendances principales :**
- numpy >= 1.21
- pandas >= 1.3
- scikit-learn >= 1.0
- optuna >= 3.0
- xgboost >= 1.5
- lightgbm >= 3.3
- catboost >= 1.0

---

## ğŸš€ Utilisation rapide

### API Python

```python
python3

import automl

# EntraÃ®nement sur un dataset
results = automl.fit("/info/corpus/ChallengeMachineLearning/data_X/data_X", mode="stable|explo")

# Afficher les rÃ©sultats
automl.eval()
```

### Exemple complet

```python
import automl

# Mode stable (rapide, ~13 modÃ¨les)
results = automl.fit(
    data_path="info/corpus/ChallengeMachineLearning/data_X/data_X",
    mode="stable",
    iterations=50,      # ItÃ©rations Optuna par modÃ¨le
    n_jobs=4            # ParallÃ©lisme
)

# Afficher le meilleur modÃ¨le
print(f"Meilleur: {results['best_models'][0]}")

# Mode exploratoire (exhaustif, ~27 modÃ¨les)
results_explo = automl.fit("info/corpus/ChallengeMachineLearning/data_X/data_X", mode="explo", iterations=10)
```

### Multi-datasets

```python
import automl

datasets = [
    {"file": "info/corpus/ChallengeMachineLearning/data_X/data_X", "expected": "classification"},
    {"file": "info/corpus/ChallengeMachineLearning/data_X/data_X", "expected": "regression"},
    {"file": "info/corpus/ChallengeMachineLearning/data_X/data_X", "expected": "multi-label"},
]

# Traitement par lot avec checkpoints automatiques
all_results = automl.fit_multiple(datasets, mode="stable")
```

---

## ğŸ“ Format des donnÃ©es

Le package attend des fichiers au format suivant :

```
data/
â”œâ”€â”€ my_dataset.data      # Features (dense ou SVMLight sparse)
â””â”€â”€ my_dataset.solution  # Target (une ou plusieurs colonnes)
```

### Format dense (.data)

```
1.5 2.3 0.8 4.1
2.1 1.9 0.5 3.8
...
```

### Format sparse SVMLight (.data)

```
0:1.5 2:0.8 10:4.1
1:2.1 2:0.5 8:3.8
...
```

### Target (.solution)

```
0
1
0
...
```

Ou multi-label :
```
1 0 1
0 1 0
1 1 0
...
```

---

## ğŸ”§ Configuration

### ParamÃ¨tres de `fit()`

| ParamÃ¨tre | Type | DÃ©faut | Description |
|-----------|------|--------|-------------|
| `data_path` | str | - | Chemin vers le dataset (sans extension) |
| `mode` | str | `"stable"` | `"stable"` ou `"explo"` |
| `iterations` | int | `50` | Nombre d'itÃ©rations Optuna |
| `n_jobs` | int | `2` | Nombre de processus parallÃ¨les |
| `autosave_interval` | int | `600` | Intervalle sauvegarde auto (secondes) |

### Modes disponibles

| Mode | ModÃ¨les | Vitesse | Usage |
|------|---------|---------|-------|
| `stable` | ~13-16 | âš¡ Rapide | Production, datasets volumineux |
| `explo` | ~25-30 | ğŸ¢ Lent | Exploration, benchmarking |

---

## ğŸ“Š ModÃ¨les supportÃ©s

### Classification

| Mode | ModÃ¨les |
|------|---------|
| **Stable** | LogisticRegression, RandomForest, GradientBoosting, XGBoost, LightGBM, CatBoost, SVC, MLP, GaussianNB... |
| **Explo** | + AdaBoost, ExtraTrees, HistGradientBoosting, NuSVC, KNN, NaiveBayes variants, LDA, QDA, GaussianProcess... |

### RÃ©gression

| Mode | ModÃ¨les |
|------|---------|
| **Stable** | LinearRegression, Ridge, Lasso, ElasticNet, RandomForest, GradientBoosting, XGBoost, LightGBM, CatBoost, SVR, MLP... |
| **Explo** | + BayesianRidge, HuberRegressor, AdaBoost, HistGradientBoosting, GaussianProcess... |

---

## ğŸ“‚ Structure du projet

```
automl/
â”œâ”€â”€ __init__.py              # API publique (fit, eval)
â”œâ”€â”€ _config.py               # Configuration globale
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trainer.py           # fit(), fit_multiple()
â”‚   â”œâ”€â”€ runner.py            # run_all_models()
â”‚   â””â”€â”€ evaluator.py         # eval(), show_results()
â”‚
â”œâ”€â”€ classification/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ _base.py             # Params & evaluate_model communs
â”‚   â”œâ”€â”€ stable.py            # Mode stable
â”‚   â””â”€â”€ explo.py             # Mode exploratoire
â”‚
â”œâ”€â”€ regression/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ _base.py
â”‚   â”œâ”€â”€ stable.py
â”‚   â””â”€â”€ explo.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logging.py           # log(), save_checkpoint()
â”‚   â”œâ”€â”€ io.py                # load_data(), importer()
â”‚   â”œâ”€â”€ cleaning.py          # auto_clean(), verif_quality()
â”‚   â”œâ”€â”€ detection.py         # detect_type_model()
â”‚   â””â”€â”€ optuna.py            # optuna_search()
â”‚
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”„ Pipeline de traitement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   load_data()   â”‚  Chargement .data + .solution
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ detect_type()   â”‚  Classification / RÃ©gression / Multi-label
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  auto_clean()   â”‚  Imputation, Encodage, Scaling
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ run_all_models()â”‚  Test parallÃ¨le + Optuna
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    RÃ©sultats    â”‚  Classement + Sauvegarde
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¾ Fichiers gÃ©nÃ©rÃ©s

```
logs/
â”œâ”€â”€ automl_stable_log.txt       # Logs d'exÃ©cution
â”œâ”€â”€ classification_stable_log.txt
â””â”€â”€ regression_stable_log.txt

checkpoints/
â”œâ”€â”€ best_model_binary-classification_stable.pkl
â””â”€â”€ checkpoint_stable.pkl       # Reprise automatique

results/
â”œâ”€â”€ results_stable.pkl          # RÃ©sultats finaux
â””â”€â”€ results_explo.pkl
```

---

## ğŸ–¥ï¸ CLI (Ligne de commande)

### Afficher les rÃ©sultats

```bash
# Via le point d'entrÃ©e installÃ©
automl-results --mode stable --top 10

# Ou directement
python -m automl.core.evaluator --mode explo
```

### Options CLI

| Option | Description |
|--------|-------------|
| `--mode` | `stable` ou `explo` |
| `--top` | Nombre de modÃ¨les Ã  afficher (dÃ©faut: 5) |
| `--dir` | RÃ©pertoire contenant les rÃ©sultats |

---

## ğŸ§ª Exemple de rÃ©sultats

```
==================================================
ğŸ“ Dataset: info/corpus/ChallengeMachineLearning/data_X/data_X
   Type: multi-classification

   ğŸ† Top 5 modÃ¨les:
   1. RandomForestClassifier          | Score: 0.9667
   2. GradientBoostingClassifier      | Score: 0.9667
   3. XGBClassifier                   | Score: 0.9333
   4. LGBMClassifier                  | Score: 0.9333
   5. SVC                             | Score: 0.9333
```

---

## âš ï¸ Gestion des erreurs

Le pipeline gÃ¨re automatiquement :

- **Interruptions** (Ctrl+C) : Sauvegarde checkpoint avant arrÃªt
- **Erreurs modÃ¨les** : Skip et log, continue avec les autres
- **MÃ©moire** : RÃ©duction automatique `n_jobs` si dataset volumineux
- **Datasets sparse** : DÃ©tection et traitement optimisÃ©

```python
# Reprise automatique aprÃ¨s interruption
results = automl.fit("data/big_dataset", mode="stable")
# Si interrompu, relancer la mÃªme commande reprend oÃ¹ Ã§a s'Ã©tait arrÃªtÃ©
```

---

## ğŸ”§ Configuration avancÃ©e

### Modifier les rÃ©pertoires

```python
import automl._config as config

config.LOG_DIR = Path("/custom/logs")
config.RESULTS_DIR = Path("/custom/results")
config.CHECKPOINT_DIR = Path("/custom/checkpoints")
```

### Personnaliser les paramÃ¨tres par dÃ©faut

```python
from automl.classification._base import DEFAULT_PARAMS_STABLE

# Modifier les paramÃ¨tres d'un modÃ¨le
DEFAULT_PARAMS_STABLE["RandomForestClassifier"]["n_estimators"] = 200
```

---

## ğŸ¤ Contribuer

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commit (`git commit -m 'Ajout fonctionnalitÃ© X'`)
4. Push (`git push origin feature/nouvelle-fonctionnalite`)
5. Ouvrir une Pull Request

---

## ğŸ“ TODO

- [ ] Corriger `regression/explo.py` (actuellement template)
- [ ] Ajouter support CSV/Parquet natif
- [ ] Interface web (Streamlit/Gradio)
- [ ] Export modÃ¨le entraÃ®nÃ© (pickle/joblib/ONNX)
- [ ] MÃ©triques supplÃ©mentaires (F1, AUC, RMSE...)
- [ ] Cross-validation optionnelle
- [ ] Feature importance automatique

---

## ğŸ“„ Licence

MIT License - voir [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ‘¥ Auteurs
- **Aymeric** - *DÃ©veloppement initital*
- **Vanessa** - *DÃ©veloppement*

---

## ğŸ™ Remerciements

- [scikit-learn](https://scikit-learn.org/)
- [Optuna](https://optuna.org/)
- [XGBoost](https://xgboost.readthedocs.io/)
- [LightGBM](https://lightgbm.readthedocs.io/)
- [CatBoost](https://catboost.ai/)
```

---

## ğŸ“‹ RÃ©capitulatif de tous les fichiers du package

| Fichier | Statut |
|---------|--------|
| `pyproject.toml` | âœ… |
| `requirements.txt` | âœ… |
| `README.md` | âœ… |
| `automl/__init__.py` | âœ… |
| `automl/_config.py` | âœ… |
| `automl/core/__init__.py` | âœ… |
| `automl/core/trainer.py` | âœ… |
| `automl/core/runner.py` | âœ… |
| `automl/core/evaluator.py` | âœ… |
| `automl/utils/__init__.py` | âœ… |
| `automl/utils/logging.py` | âœ… |
| `automl/utils/io.py` | âœ… |
| `automl/utils/cleaning.py` | âœ… |
| `automl/utils/detection.py` | âœ… |
| `automl/utils/optuna.py` | âœ… |
| `automl/classification/__init__.py` | âœ… |
| `automl/classification/_base.py` | âœ… |
| `automl/classification/stable.py` | âœ… |
| `automl/classification/explo.py` | âœ… |
| `automl/regression/__init__.py` | âœ… |
| `automl/regression/_base.py` | âœ… |
| `automl/regression/stable.py` | âœ… |
| `automl/regression/explo.py` | âš ï¸ Template (Ã  complÃ©ter) |
